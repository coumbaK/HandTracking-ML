# A9: Hand Tracking

## Your name
Mame Coumba KA

## Your Glitch link
[my page](https://galaxykate-a9.glitch.me)


## Describe the experience you designed
I wanted to create something similar to Just Dance using the song Baby Shark and dance gestures.

## For each hand gesture it responds to, what does it do?
My initial idea was to compare every gesture with the right move according to the song and choreography then similar to Just Dance give feedback to the use on how they are doing. I wasn't able to entirely implment this so my code checks that the hand tracking recognizes the right label at the right part of the song which means the user is doing the right move.

## How are you visualizing or changing graphics with the gesture?
I was not able to visualize but I wanted to show pop up icons everytime the user did the right dance move.

## What gestures mentioned in the Lingthusiasm podcast are related to your gestures?
 none.


## How long did it take to train your network with this Handsfree-handtracking approach?
I trained multiple times because my loss value was either infinite or too high then i finally got a loss value of 0.6 after training. 


## Which gestures did it guess wrong and when? What could have improved that training data?
 


## How long did it take to train the network with the Teachable Machine pixel-based approach?

--your answer here--



## How did the quality of predictions compare between them?

--your answer here--


## How did the quality of predictions on Teachable Machine change when you changed the background or lighting?

--your answer here--

## List any resources (code, images, etc) you've used, and where you got them from

--your answer here--

## List any help you got from classmates or websites, so that you can remember it for later

--your answer here--